### 同步脚本

```
#!/bin/bash

#1. 判断参数个数
if [ $# -lt 1 ]
then
    echo Not Enough Arguement!
    exit;
fi

#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
    echo ====================  $host  ==================== 
    #3. 遍历所有目录，挨个发送

    for file in $@ -----------------$@当前目录下所有文件
    do
        #4. 判断文件是否存在
        if [ -e $file ]-------------(-e)是查看是否存在
            then
                #5. 获取父目录
                pdir=$(cd -P $(dirname $file); pwd)
------------cd -P：这表示改变当前工作目录并遵循物理路径（即符号链接将被跳过）；即，有软连接的是保持在符号链接指向的目录位置。
                #6. 获取当前文件的名称
                fname=$(basename $file)
                ssh $host "mkdir -p $pdir"---------如果没有目录就创建目录
                rsync -av $pdir/$fname $host:$pdir------父级目录/子目录
                --------------$host:$pdir表示远程主机上目标路径的目录。
            else
                echo $file does not exists!
        fi
    done
done
```

#### 公钥与私钥

A通过ssh-keygen可以生成公钥和私钥

A把私钥保存本地，把公钥给B

A给B发数据，A用私钥加密，B用公钥解密

B给A发数据，B用公钥加密，A用私钥解密

known_hosts记录访问过的机器的公钥

```
[had@hadoop102 ~]$ start-dfs.sh
Starting namenodes on [hadoop102]
Starting datanodes
hadoop103: WARNING: /opt/module/hadoop-3.3.4/logs does not exist. Creating.
hadoop101: WARNING: /opt/module/hadoop-3.3.4/logs does not exist. Creating.
Starting secondary namenodes [hadoop103]
```

警告的问题是没有目录需要创建一下

```
[had@hadoop102 ~]$ jps-----------java ps
11715 Jps
11431 DataNode
11291 NameNode
```

102有NameNode

```
[had@hadoop103 ~]$ jps
5959 SecondaryNameNode
6055 Jps
5869 DataNode

启动yarn
[had@hadoop103 ~]$ jps
6405 NodeManager
5959 SecondaryNameNode
6762 Jps
6283 ResourceManager
5869 DataNode
```

103有SecondaryNameNode

```
[had@hadoop101 ~]$ jps
5828 DataNode
5918 Jps
```

101什么都没有

|      | 102                    | 103                              | 104                             |
| ---- | ---------------------- | -------------------------------- | ------------------------------- |
| HDFS | **NameNode**  DataNode | DataNode                         | **SecondaryNameNode**  DataNode |
| Yarn | NodeManager            | **ResourceManager**  NodeManager | NodeManager                     |



http://192.168.20.102:9870/

http://192.168.20.103:8088/







#### 没有图标，连接不到有线网络

![img](https://i-blog.csdnimg.cn/blog_migrate/2fe0715a93f1e1891f22a32ec6824077.png)![img](https://i-blog.csdnimg.cn/blog_migrate/851a8b2d4bef195cce5fcd489e67d6fd.png)

```
# 关闭网路
service NetworkManager stop
# 删除NetworkManager缓存文件
sudo rm /var/lib/NetworkManager/NetworkManager.state
# 打开网络
service NetworkManager start
```











hadoop

```linux
[had@hadoop102 ~]$ hadoop fs -ls /
Found 6 items
drwxr-xr-x   - had supergroup          0 2025-01-06 01:52 /c01
drwxr-xr-x   - had supergroup          0 2025-01-06 00:29 /input
drwx------   - had supergroup          0 2025-01-06 01:15 /tmp
drwxr-xr-x   - had supergroup          0 2025-01-06 00:31 /wcoutput
drwxr-xr-x   - had supergroup          0 2025-01-06 00:46 /wcoutput2
drwxr-xr-x   - had supergroup          0 2025-01-06 01:15 /wcoutput3
```

