#  Mapreduce

## mapreduce介绍

hadoop核心之一

- MRAppMaster：负责整个程序的调度机状态协调
- MapTask：负责map阶段整个数据处理流程
- ReduceTask：负责reduce阶段整个数据处理流程

## 设计思想

- 简化并行计算的编程模型
- 开发人员专注于实现Mapper和Reducer函数
- 开发人员专注于业务逻辑实现

## MaperReduce优点

1. 易于编程，简单实现接口就可完成一个分布式程序，可以分不到大量廉价的pc机器上运行，（**分布式程序和串行程序类似**）
2. 良好的扩展性：通过动态的增加机器来扩展他的能力
3. 高容错性：能部署在廉价的pc机器上，要求有很高的容错性，可以把任务转移到其他节点上运行，不至于运行失败，hadoop内部完成
4. 处理海量离线数据：实现上千台服务器集群并发工作，
5. 资源不足时也能运行，速度慢，不至于程序启动失败（spark：资源不足时不运行）

## MapReduce缺点

1. 不擅长实时计算，延迟高
2. 不擅长流式计算
3. 不擅长DAG（有向无环图）计算

多个应用程序存在依赖关系，后一个应用程序的输出会为前一个输出

每个MapReduce作业输出结果都会写入磁盘，再从磁盘读取，会造成自盘io导致性能低下

Mapeduce流程（WorkCont）

![PixPin_2025-01-09_14-19-20](C:\Users\陈宣玮\Desktop\截图\PixPin_2025-01-09_14-19-20.png)

## 序列化

## MapReduce编程规范

### Mapper

- 自定义类继承Mapper
- Mapper输入数据时KV对形式
- Mapper中的业务逻辑写在map（）方法里
- Mapper的输出数据是KV对的形式
- map()方法对每个<K,V>调用一次

### Reducer

- 自定义类，继承Reducer
- Reducer的输出数据类型对应Mapper的输出数据类型也是KV
- Reducer的业务逻辑写在reducer（）方法中
- ReduceTask进程对每一组相同k的<k，v>组调用一次reduce()方法

### Driver

yarn集群的客户端，提交程序到yarn集群，提交的是封装的MapReduce程序相关运行参数的job对象



```java
package com.bigdata.d0109;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.VLongWritable;
import org.apache.hadoop.mapreduce.Mapper;
import java.io.IOException;
public class WordCountMapper extends Mapper<VLongWritable,Text, Text, IntWritable> {
    @Override
    protected void map(VLongWritable key, Text value,
                       Mapper<VLongWritable, Text, Text, IntWritable>.Context context)
            throws IOException, InterruptedException {
        String line = value.toString();//把输入的Text值转换为普通的String类型
        String[] words = line.split("");//将这一行文本按字符拆分成字符串数组
        for(String word : words){
            Text k = new Text();//创建一个Text类型的键（k），它将用来存储当前字符。
            IntWritable v = new IntWritable(1);
            k.set(word);//将当前字符设置为Text类型的键。
            context.write(k,v);//将k，v写入到context输出到下一个阶段
        }//对于每个单独的字符，生成一个输出键值对。
    }
}
```



```java
package com.bigdata.d0109;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.mapreduce.Reducer;
import org.junit.Test;
import java.io.IOException;

public class WordCountReducer extends Reducer<Test, IntWritable,Test, IntWritable> {
    @Override
    protected void reduce(Test key, Iterable<IntWritable> values, 
    					Reducer<Test, IntWritable, Test, IntWritable>.Context context) 
    		throws IOException, InterruptedException {
         int sum = 0;
         for(IntWritable count : values){
             sum += count.get();
         }//定义一个 sum 变量来累加 values 中的每个 IntWritable 对象的值
             IntWritable v = new IntWritable();
         v.set(sum);
         context.write(key,v);
    }
}
```



```java
package com.bigdata.d0109;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCountDriver {
    public static void main(String[] args) throws Exception {
        Configuration conf= new Configuration();//创建一个 Hadoop 配置对象，包含了作业所需的配置信息
        Job job = Job.getInstance(conf);
        //创建一个新的作业实例，Job 是 Hadoop 中的核心类，表示一个 MapReduce 作业。getInstance(conf) 方法从配置对象中获取默认配置并初始化作业实例。
        job.setJarByClass(WordCountDriver.class);
        job.setMapperClass(WordCountMapper.class);
        job.setReducerClass(WordCountReducer.class);
        
        
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        
        FileInputFormat.setInputPaths(job,new Path("E:\\xiangmu\\Hadoopc01\\file\\input"));
        FileOutputFormat.setOutputPath(job,new Path("E:\\xiangmu\\Hadoopc01\\file\\output"));
        boolean result = job.waitForCompletion(true); 
        System.exit(result ? 0 : 1);
    }
}
```

