### WriteableComparable排序

MapTask和ReduceTask 都会对数据按照key排序

排序规则是字典顺序，排序算法是快速排序









### 排序分类

- 部分排序
- 全排序
- 辅助排序
- 二次排序

全排序、

```
import lombok.Getter;
import lombok.Setter;
import org.apache.hadoop.io.WritableComparable;

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;
@Getter
@Setter
public class StudentBean implements WritableComparable<StudentBean> {
    private int stuId;
    private String name;
    private String subject;
    private double score;
    public StudentBean(){}


    @Override
    public void write(DataOutput out) throws IOException {
        out.writeInt(stuId);
        out.writeUTF(name);
        out.writeUTF(subject);
        out.writeDouble(score);
    }

    @Override
    public void readFields(DataInput in) throws IOException {
        this.stuId=in.readInt();
        this.name=in.readUTF();
        this.subject=in.readUTF();
        this.score=in.readDouble();
    }
    @Override
    public String toString() {
        return this.stuId +"\t"+this.name+"\t"+this.subject+"\t"+this.score;
    }


    @Override
    public int compareTo(StudentBean o) {
        if(stuId<o.getStuId()){
            return -1;
        } else if (stuId>o.getStuId()) {
            return 1;
        }else {
            if (score<o.getScore()){
                return -1;
            } else  {
                return  1;

            }
        }
    }
}
```



```
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class StudentMapper extends Mapper<LongWritable, Text,StudentBean, NullWritable> {
    @Override
    protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, StudentBean, NullWritable>.Context context) throws IOException, InterruptedException {
        String[] arr = value.toString().split("\t");
        String stuId=arr[0];
        String name = arr[1];
        String subject = arr[2];
        String score = arr[3];

        StudentBean beankey =new StudentBean();
        beankey.setStuId(Integer.valueOf(stuId));
        beankey.setName(name);
        beankey.setSubject(subject);
        beankey.setScore(Integer.valueOf(score));

        context.write(beankey,NullWritable.get());
    }
}
```



```
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class StudentReducer extends Reducer<StudentBean, NullWritable, StudentBean, NullWritable> {
    @Override
    protected void reduce(StudentBean key, Iterable<NullWritable> values, Reducer<StudentBean, NullWritable, StudentBean, NullWritable>.Context context) throws IOException, InterruptedException {
        for (NullWritable value :values) {
            context.write(key, value);
        }
    }
}

```





```
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

public class StudentDriver {
    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {
        Configuration conf=new Configuration();
        Job job = Job.getInstance(conf);

        job.setJarByClass(StudentDriver.class);

        job.setMapperClass(StudentMapper.class);
        job.setReducerClass(StudentReducer.class);

        job.setMapOutputKeyClass(StudentBean.class);
        job.setMapOutputValueClass(NullWritable.class);

        job.setOutputKeyClass(StudentBean.class);
        job.setOutputValueClass(NullWritable.class);

        job.setNumReduceTasks(1);

        String Constrootdir="E:/xiangmu/Hadoopc01/file/";
        FileInputFormat.setInputPaths(job,new Path(Constrootdir +"input/day0115"));
        FileOutputFormat.setOutputPath(job,new Path(Constrootdir+"output/day0115"));
        boolean b = job.waitForCompletion( true);
        System.exit(b ? 0:1);
    }
}
```

